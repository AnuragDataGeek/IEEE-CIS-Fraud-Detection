{"cells":[{"metadata":{"_uuid":"5e1ef7b6-5f7e-45ed-92b5-4aee9dd9e019","_cell_guid":"3f75c65b-64f0-4b36-a677-5f1edf66665e","trusted":true},"cell_type":"code","source":"# %% [code]\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport gc,sys\nimport re\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\npd.options.display.float_format = '{:,.3f}'.format\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\n# %% [code]\ntrain_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\nprint(train_identity.shape)\nprint(train_identity.head())\n\n# %% [code]\ntrain_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')\nprint(train_transaction.shape)\nprint(train_transaction.head())\n\n# %% [code]\ntest_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_identity.csv')\ntest_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv')\n\n# %% [code]\nimport matplotlib.pyplot as plt\n%matplotlib inline\ntrain_transaction.isFraud.value_counts(normalize=True).plot.bar()\n\n# %% [code]\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\n# %% [code]\ntrain_identity = reduce_mem_usage(train_identity)\ntrain_transaction = reduce_mem_usage(train_transaction)\ntest_identity = reduce_mem_usage(test_identity)\ntest_transaction = reduce_mem_usage(test_transaction)\n\n# %% [code]\ntrain_transaction['trn_day'] = train_transaction['TransactionDT']//(24*60*60)\ntrain_transaction['trn_week'] = train_transaction['trn_day']//7\n\n# %% [code]\ntrain_transaction.groupby('trn_day')['isFraud'].mean().plot.line(figsize=(15,4))\n\n\n# %% [code]\ntrain_transaction.groupby('trn_week')['isFraud'].mean().plot.line(figsize=(15,4))\n\n# %% [code]\nimport datetime as dt\nstart_date = '2017-12-01'\nstartdate = dt.datetime.strptime(start_date, \"%Y-%m-%d\")\n\ntrain_transaction['Date'] = train_transaction['TransactionDT'].apply(lambda x: (startdate + dt.timedelta(seconds=x)))\ntrain_transaction['_year_month'] = train_transaction['Date'].dt.year.astype(str) + '/' + train_transaction['Date'].dt.month.astype(str)\ntrain_transaction['_weekday'] = train_transaction['Date'].dt.dayofweek\ntrain_transaction['_hour'] = train_transaction['Date'].dt.hour\ntrain_transaction['_day'] = train_transaction['Date'].dt.day\n\nfig,ax = plt.subplots(4, 1, figsize=(16,16))\n\ntrain_transaction.groupby('_weekday')['isFraud'].mean().plot.bar(ax=ax[0])\ntrain_transaction.groupby('_hour')['isFraud'].mean().plot.bar(ax=ax[1])\ntrain_transaction.groupby('_day')['isFraud'].mean().plot.bar(ax=ax[2])\ntrain_transaction.groupby('_year_month')['isFraud'].mean().plot.bar(ax=ax[3])\n\n\n# %% [code]\ntrain_transaction['weekday_hour'] = train_transaction['_weekday'].astype(str)+'_'+train_transaction['_hour'].astype(str)\ntrain_transaction.groupby('weekday_hour')['isFraud'].mean().plot.line(figsize=(16,4))\n\n# %% [code]\ntrain_transaction['amount_qcut10'] = pd.qcut(train_transaction['TransactionAmt'],10)\nprint(train_transaction.groupby('amount_qcut10')['isFraud'].mean())\n\n# %% [code]\ntrain_id_trn = pd.merge(train_identity, train_transaction[['isFraud','TransactionID']])\ntrain_id_fraud = train_id_trn[train_id_trn['isFraud']==1]\ntrain_id_notfraud = train_id_trn[train_id_trn['isFraud']==0]\nprint(train_id_fraud.shape,train_id_notfraud.shape)\n\n# %% [code]\ndef plot1(col):\n    plt.hist([train_id_fraud[col],train_id_notfraud[col]],color=['green','blue'])\nplot1('id_01')\n\n# %% [code]\nplot1('id_02')\n\n# %% [code]\nplot1('id_07')\n\n# %% [code]\ndef plot2(col):\n    #colors = tuple(np.where(train_id_trn[\"isFraud\"]=1, 'g', 'b'))\n    train_id_trn.groupby(['isFraud'])[col].value_counts(normalize=True).plot.bar()\nplot2('id_15')\n\n# %% [code]\nplot2('id_16')\n\n# %% [code]\nplot1('id_17')\n\n# %% [code]\nplot1('id_19')\n\n# %% [code]\nplot1('id_20')\n\n# %% [code]\nplot2('id_23')\n\n# %% [code]\nplot1('id_26')\n\n# %% [code]\nplot2('id_28')\n\n# %% [code]\nplot2('id_29')\n\n# %% [code]\n#plot2('id_31')\n#train_id_trn.groupby(['isFraud'])['id_31'].value_counts(normalize=True).sort_values(ascending=False).plot.bar(figsize=(15,5))\ntrain_id_fraud.groupby(['isFraud'])['id_31'].value_counts(normalize=True).sort_values(ascending=False).plot.bar(figsize=(20,5))\n\n# %% [code]\nplot1('id_32')\n\n# %% [code]\ntrain_id_fraud.groupby(['isFraud'])['id_33'].value_counts(normalize=True).sort_values(ascending=False).plot.bar(figsize=(20,5))\n\n# %% [code]\nplot2('id_34')\n\n# %% [code]\nplot2('id_35')\n\n# %% [code]\nplot2('id_38')\n\n# %% [code]\nplot2('DeviceType')\n\n# %% [code]\ntrain_id_fraud.groupby(['isFraud'])['DeviceInfo'].value_counts(normalize=True)[:20].sort_values(ascending=False).plot.bar(figsize=(20,5))\n\n# %% [code]\nccols = [f'C{i}' for i in range(1,15)]\ndcols = [f'D{i}' for i in range(1,16)]\nmcols = [f'M{i}' for i in range(1,10)]\nvcols = [f'V{i}' for i in range(1,340)]\n\n# %% [code]\ntrain_trn_f0 = train_transaction[train_transaction['isFraud'] == 0]\ntrain_trn_f1 = train_transaction[train_transaction['isFraud'] == 1]\nprint(train_trn_f0.shape, train_trn_f1.shape)\n\ndef plotTrnHistByFraud(col, bins=20):\n    with np.errstate(invalid='ignore'):\n        plt.figure(figsize=(8,3))\n        plt.hist([train_trn_f0[col], train_trn_f1[col]], bins=bins, density=True, color=['royalblue', 'orange'])\n\ndef plotTrnLogHistByFraud(col, bins=20):\n    with np.errstate(invalid='ignore'):\n        plt.figure(figsize=(8,3))\n        plt.hist([np.log1p(train_trn_f0[col]), np.log1p(train_trn_f1[col])], bins=bins, density=True, color=['royalblue', 'orange'])\n        \ndef plotTrnCategoryRateBar(col, topN=np.nan):\n    a, b = train_trn_f0, train_trn_f1\n    if topN == topN: # isNotNan\n        vals = b[col].value_counts(normalize=True).to_frame().iloc[:topN,0]\n        subA = a.loc[a[col].isin(vals.index.values), col]\n        df = pd.DataFrame({'normal':subA.value_counts(normalize=True), 'fraud':vals})\n    else:\n        df = pd.DataFrame({'normal':a[col].value_counts(normalize=True), 'fraud':b[col].value_counts(normalize=True)})\n    df.sort_values('fraud', ascending=False).plot.bar(figsize=(8,3))\n\n\n# %% [code]\ndef appendLagDT(df):\n    df = df.assign(_date_lag = df['TransactionDT'] - df.groupby(['card1','card2'])['TransactionDT'].shift(1))\n    return df\n\ntrain_transaction = appendLagDT(train_transaction)\ntrain_trn_f0 = train_transaction[train_transaction['isFraud'] == 0]\ntrain_trn_f1 = train_transaction[train_transaction['isFraud'] == 1]\n\n# %% [code]\npd.concat([train_trn_f0['_date_lag'].describe(), \n           train_trn_f1['_date_lag'].describe()], axis=1)\n\n# %% [code]\nplotTrnLogHistByFraud('_date_lag')\n\n# %% [code]\nplotTrnHistByFraud('TransactionAmt')\nplotTrnLogHistByFraud('TransactionAmt')\n\n# %% [code]\nprint(\"Normal\")\nprint(train_trn_f0['TransactionAmt'].describe())\nprint(\"Fraud\")\nprint(train_trn_f1['TransactionAmt'].describe())\n\n# %% [code]\ndef appendLagAmt(df):\n    df = df.assign(_amt_lag = df['TransactionAmt'] - df.groupby(['card1','card2'])['TransactionAmt'].shift(1))\n    df['_amt_lag_sig'] = df['_amt_lag'].apply(lambda x: '0' if np.isnan(x) else '+' if x >=0 else '-')\n    return df\n\ntrain_transaction = appendLagAmt(train_transaction)\ntrain_trn_f0 = train_transaction[train_transaction['isFraud'] == 0]\ntrain_trn_f1 = train_transaction[train_transaction['isFraud'] == 1]\n\n# %% [code]\nplotTrnHistByFraud('_amt_lag')\nplotTrnCategoryRateBar('_amt_lag_sig')\n\n# %% [code]\nplotTrnCategoryRateBar('ProductCD')\n\n# %% [code]\n\ntrain_transaction['_amount_max_ProductCD'] = train_transaction.groupby(['ProductCD'])['TransactionAmt'].transform('max')\ntrain_transaction[['ProductCD','_amount_max_ProductCD']].drop_duplicates().sort_values(by='_amount_max_ProductCD', ascending=False)\n\n# %% [code]\nplotTrnCategoryRateBar('card1', 15)\nplotTrnHistByFraud('card1', bins=30)\n\n# %% [code]\nplotTrnCategoryRateBar('card2', 15)\nplotTrnHistByFraud('card2', bins=30)\n\n# %% [code]\nplotTrnCategoryRateBar('card3', 10)\n\n# %% [code]\nplotTrnCategoryRateBar('card4')\n\n# %% [code]\nplotTrnCategoryRateBar('card5', 10)\n\n# %% [code]\nplotTrnCategoryRateBar('card6')\n\n# %% [code]\nprint(len(train_transaction))\nprint(train_transaction['card1'].nunique(), train_transaction['card2'].nunique(), train_transaction['card3'].nunique(), train_transaction['card5'].nunique())\n\ntrain_transaction['card_n'] = (train_transaction['card1'].astype(str) + '_' + train_transaction['card2'].astype(str) \\\n       + '_' + train_transaction['card3'].astype(str) + '_' + train_transaction['card5'].astype(str))\nprint('unique cards:', train_transaction['card_n'].nunique())\n\n# %% [code]\ntrain_transaction['card_n'].value_counts().sort_values(ascending=False)[:40].plot.bar(figsize=(15,3))\n\n# %% [code]\ntrain_transaction.groupby(['card_n'])['isFraud'].mean().sort_values(ascending=False)\n\n# %% [code]\nplotTrnCategoryRateBar('addr1', 20)\nplotTrnHistByFraud('addr1', bins=30)\n\n# %% [code]\nplotTrnCategoryRateBar('dist1', 20)\nplotTrnCategoryRateBar('dist2', 20)\n\n# %% [code]\nplotTrnCategoryRateBar('P_emaildomain',10)\nplotTrnCategoryRateBar('R_emaildomain',10)\n\n# %% [code]\ntrain_transaction['P_emaildomain'].cat.add_categories('unknown').fillna('unknown',inplace=True)\ntrain_transaction['R_emaildomain'].cat.add_categories('unknown').fillna('unknown',inplace=True)\n\n\n# %% [code]\ntrain_trn_f1['P_emaildomain_prefix'] = train_trn_f1['P_emaildomain'].cat.add_categories('unknown').fillna('unknown').apply(lambda x: x.split('.')[0])\npd.crosstab(train_trn_f1['P_emaildomain_prefix'], train_trn_f1['ProductCD']).T\n\n# %% [code]\ntrain_transaction['P_emaildomain_prefix'] = train_transaction['P_emaildomain'].apply(lambda x: x.split('.')[0])\nct = pd.crosstab(train_transaction['P_emaildomain_prefix'], train_transaction['ProductCD'])\nct = ct.sort_values(by='W')[-15:]\nct.plot.barh(stacked=True, figsize=(12,4))\n\n# %% [code]\nfor i in range(1,15):\n    plotTrnCategoryRateBar(f'C{i}',10)\n\n# %% [code]\ntrain_transaction[ccols].describe().loc[['count','mean','std','min','max']]\n\n# %% [code]\nplt.figure(figsize=(10,5))\n\ncorr = train_transaction[['isFraud'] + ccols].corr()\nsns.heatmap(corr, annot=True, fmt='.2f')\n\n# %% [code]\nfor i in range(1,16):\n    plotTrnCategoryRateBar(f'D{i}',10)\n\n# %% [code]\ntrain_transaction[dcols].describe().loc[['count','mean','std','min','max']]\n\n# %% [code]\nplt.figure(figsize=(12,4))\n\nplt.scatter(train_trn_f0['TransactionDT'], train_trn_f0['D1'], s=2)\nplt.scatter(train_trn_f1['TransactionDT'], train_trn_f1['D1'], s=2, c='r')\n\n\n# %% [code]\nplt.scatter(test_transaction['TransactionDT'], test_transaction['D1'], s=2, c='g')\n\n# %% [code]\nplt.figure(figsize=(12,4))\n\nplt.scatter(train_trn_f0['TransactionDT'], train_trn_f0['D15'], s=2)\nplt.scatter(train_trn_f1['TransactionDT'], train_trn_f1['D15'], s=2, c='r')\nplt.scatter(test_transaction['TransactionDT'], test_transaction['D15'], s=2, c='g')\n\n# %% [code]\nplt.figure(figsize=(10,5))\n\ncorr = train_transaction[['isFraud'] + dcols].corr()\nsns.heatmap(corr, annot=True, fmt='.2f')\n\n# %% [code]\nfig, ax = plt.subplots(1, 2, figsize=(15, 3))\ntrain_transaction.loc[train_transaction['isFraud']==0, dcols].isnull().sum(axis=1).to_frame().hist(ax=ax[0], bins=20)\ntrain_transaction.loc[train_transaction['isFraud']==1, dcols].isnull().sum(axis=1).to_frame().hist(ax=ax[1], bins=20)\n\n# %% [code]\nplotTrnCategoryRateBar('M1')\nplotTrnCategoryRateBar('M2')\nplotTrnCategoryRateBar('M3')\nplotTrnCategoryRateBar('M4')\n\n# %% [code]\nplotTrnCategoryRateBar('M5')\nplotTrnCategoryRateBar('M6')\nplotTrnCategoryRateBar('M7')\nplotTrnCategoryRateBar('M8')\nplotTrnCategoryRateBar('M9')\n\n# %% [code]\nfig, ax = plt.subplots(1, 2, figsize=(15, 3))\ntrain_transaction.loc[train_transaction['isFraud']==0, vcols].isnull().sum(axis=1).to_frame().hist(ax=ax[0], bins=20)\ntrain_transaction.loc[train_transaction['isFraud']==1, vcols].isnull().sum(axis=1).to_frame().hist(ax=ax[1], bins=20)\n\n# %% [code]\ntrain_id = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\ntrain_trn = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')\ntest_id = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_identity.csv')\ntest_trn = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv')\n\nid_cols = list(train_id.columns.values)\ntrn_cols = list(train_trn.drop('isFraud', axis=1).columns.values)\n\nX_train = pd.merge(train_trn[trn_cols + ['isFraud']], train_id[id_cols], how='left')\nX_train = reduce_mem_usage(X_train)\nX_test = pd.merge(test_trn[trn_cols], test_id[id_cols], how='left')\nX_test = reduce_mem_usage(X_test)\n\nX_train_id = X_train.pop('TransactionID')\nX_test_id = X_test.pop('TransactionID')\ndel train_id,train_trn,test_id,test_trn\n\nall_data = X_train.append(X_test, sort=False).reset_index(drop=True)\n\n# %% [code]\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.decomposition import PCA\nvcols=[f'V{i}' for i in range(1,340)]\n\nsc = MinMaxScaler()\n\npca = PCA(n_components=2) #0.99\nvcol_pca = pca.fit_transform(sc.fit_transform(all_data[vcols].fillna(-1)))\n\nall_data['_vcol_pca0'] = vcol_pca[:,0]\nall_data['_vcol_pca1'] = vcol_pca[:,1]\nall_data['_vcol_nulls'] = all_data[vcols].isnull().sum(axis=1)\n\nall_data.drop(vcols, axis=1, inplace=True)\n\n# %% [code]\nimport datetime\n\nSTART_DATE = '2017-12-01'\nstartdate = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\")\nall_data['Date'] = all_data['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\nall_data['_weekday'] = all_data['Date'].dt.dayofweek\nall_data['_hour'] = all_data['Date'].dt.hour\nall_data['_day'] = all_data['Date'].dt.day\n\nall_data['_weekday'] = all_data['_weekday'].astype(str)\nall_data['_hour'] = all_data['_hour'].astype(str)\nall_data['_weekday__hour'] = all_data['_weekday'] + all_data['_hour']\n\ncnt_day = all_data['_day'].value_counts()\ncnt_day = cnt_day / cnt_day.mean()\nall_data['_count_rate'] = all_data['_day'].map(cnt_day.to_dict())\n\nall_data.drop(['TransactionDT','Date','_day'], axis=1, inplace=True)\n\n# %% [code]\nall_data['_P_emaildomain__addr1'] = all_data['P_emaildomain'] + '__' + all_data['addr1'].astype(str)\nall_data['_card1__card2'] = all_data['card1'].astype(str) + '__' + all_data['card2'].astype(str)\nall_data['_card1__addr1'] = all_data['card1'].astype(str) + '__' + all_data['addr1'].astype(str)\nall_data['_card2__addr1'] = all_data['card2'].astype(str) + '__' + all_data['addr1'].astype(str)\nall_data['_card12__addr1'] = all_data['_card1__card2'] + '__' + all_data['addr1'].astype(str)\nall_data['_card_all__addr1'] = all_data['_card1__card2'] + '__' + all_data['addr1'].astype(str)\n\n# %% [code]\nall_data['_amount_decimal'] = ((all_data['TransactionAmt'] - all_data['TransactionAmt'].astype(int)) * 1000).astype(int)\nall_data['_amount_decimal_len'] = all_data['TransactionAmt'].apply(lambda x: len(re.sub('0+$', '', str(x)).split('.')[1]))\nall_data['_amount_fraction'] = all_data['TransactionAmt'].apply(lambda x: float('0.'+re.sub('^[0-9]|\\.|0+$', '', str(x))))\nall_data[['TransactionAmt','_amount_decimal','_amount_decimal_len','_amount_fraction']].head(10)\n\n# %% [code]\ncols = ['ProductCD','card1','card2','card5','card6','P_emaildomain','_card_all__addr1']\n\n\n# amount mean&std\nfor f in cols:\n    all_data[f'_amount_mean_{f}'] = all_data['TransactionAmt'] / all_data.groupby([f])['TransactionAmt'].transform('mean')\n    all_data[f'_amount_std_{f}'] = all_data['TransactionAmt'] / all_data.groupby([f])['TransactionAmt'].transform('std')\n    all_data[f'_amount_pct_{f}'] = (all_data['TransactionAmt'] - all_data[f'_amount_mean_{f}']) / all_data[f'_amount_std_{f}']\n\n# freq encoding\nfor f in cols:\n    vc = all_data[f].value_counts(dropna=False)\n    all_data[f'_count_{f}'] = all_data[f].map(vc)\n\n\n# %% [code]\ncat_cols = [f'id_{i}' for i in range(12,39)]\nfor i in cat_cols:\n    if i in all_data.columns:\n        all_data[i] = all_data[i].astype(str)\n        all_data[i].fillna('unknown', inplace=True)\n\nenc_cols = []\nfor i, t in all_data.loc[:, all_data.columns != 'isFraud'].dtypes.iteritems():\n    if t == object:\n        enc_cols.append(i)\n        #df = pd.concat([df, pd.get_dummies(df[i].astype(str), prefix=i)], axis=1)\n        #df.drop(i, axis=1, inplace=True)\n        all_data[i] = pd.factorize(all_data[i])[0]\n        #all_data[i] = all_data[i].astype('category')\nprint(enc_cols)\n\n# %% [code]\nall_data['isFraud'].isnull().sum()\nX_train = all_data[all_data['isFraud'].notnull()]\nX_test = all_data[all_data['isFraud'].isnull()].drop('isFraud',axis=1)\nY_train = X_train.pop('isFraud')\n\n# %% [code]\nprint(X_train.shape,X_test.shape)\n\n# %% [code]\n%%time\nfrom mlxtend.classifier import StackingClassifier\nimport lightgbm as lgb\n\nparams={'learning_rate': 0.01,\n        'objective': 'binary',\n        'metric': 'auc',\n        'num_threads': -1,\n        'num_leaves': 256,\n        'verbose': 1,\n        'random_state': 42,\n        'bagging_fraction': 1,\n        'feature_fraction': 0.85\n       }\n\noof_preds = np.zeros(X_train.shape[0])\nsub_preds = np.zeros(X_test.shape[0])\n\nclf1 = lgb.LGBMClassifier(**params, n_estimators=3000)\n#clf.fit(X_train, Y_train)\n#oof_preds = clf.predict_proba(X_train, num_iteration=clf.best_iteration_)[:,1]\n#sub_preds = clf.predict_proba(X_test, num_iteration=clf.best_iteration_)[:,1]\n\n# %% [code]\nparams2={'learning_rate': 0.005,\n        'objective': 'binary',\n        'metric': 'auc',\n        'num_threads': -1,\n        'num_leaves': 512,\n        'verbose': 1,\n        'random_state': 41,\n        'bagging_fraction': 1,\n        'feature_fraction': 0.85\n       }\nclf2=lgb.LGBMClassifier(**params2, n_estimators=4000)\n\n# %% [code]\nparams3={'learning_rate': 0.007,\n        'objective': 'binary',\n        'metric': 'auc',\n        'num_threads': -1,\n        'num_leaves': 384,\n        'verbose': 1,\n        'random_state': 41,\n        'bagging_fraction': 1,\n        'feature_fraction': 0.85\n       }\nclf3=lgb.LGBMClassifier(**params3, n_estimators=3500)\n\n# %% [code]\nsclf=StackingClassifier(classifiers=[clf1,clf2],use_probas=True,meta_classifier=clf3)\nsclf.fit(X_train, Y_train)\noof_preds = sclf.predict_proba(X_train, num_iteration=sclf.best_iteration_)[:,1]\nsub_preds = sclf.predict_proba(X_test, num_iteration=sclf.best_iteration_)[:,1]\n\n# %% [code]\nsubmission = pd.DataFrame()\nsubmission['TransactionID'] = X_test_id\nsubmission['isFraud'] = sub_preds\nsubmission.to_csv('submission1.csv', index=False)","execution_count":0,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}